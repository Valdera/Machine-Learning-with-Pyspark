{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411a66ba-f0f4-46c0-9eb8-f481f96f53c3",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0068be-4e60-4d8d-8d98-3f080e1d0a6d",
   "metadata": {},
   "source": [
    "## Step 1: Create the SparkSession Object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc874f6-7d28-4310-96d4-a1f32cd62e88",
   "metadata": {},
   "source": [
    "We start the Jupyter Notebook and import `SparkSession` and create a new \n",
    "`SparkSession` object to use Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72502b8c-8421-4bcc-923d-f2fd8a58acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9c12db-96ff-4fd2-bb46-d324851803b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('random_forest').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e9bfb5-05e2-4762-8b9b-262e5b7ea755",
   "metadata": {},
   "source": [
    "## Step 2: Read the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f179a08-a093-45cc-99c7-8b58def92751",
   "metadata": {},
   "source": [
    "We then load and read the dataset within Spark using Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19bb4d3b-169d-4141-ae68-eba5f96f66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('affairs.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840b24c-e788-4d78-a7df-6116d82b6537",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe1c57-ed33-482c-9ad4-c392e0ba7121",
   "metadata": {},
   "source": [
    "In this section, we drill deeper into the dataset by viewing the dataset and \n",
    "validating the shape of the dataset and various statistical measures of the \n",
    "variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b45e291-6a2a-4066-b027-45388b2c3bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a64253-f420-442b-b36b-bedda914c72b",
   "metadata": {},
   "source": [
    "So, the above output confirms the size of our dataset and we can then \n",
    "validate the data types of the input values to check if we need to change/\n",
    "cast any columns data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8107f064-09d4-4dc6-8bbf-1b574dad5b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rate_marriage: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- yrs_married: double (nullable = true)\n",
      " |-- children: double (nullable = true)\n",
      " |-- religious: integer (nullable = true)\n",
      " |-- affairs: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba86c70-cfd2-47ce-8bed-b984ab794af8",
   "metadata": {},
   "source": [
    "Let’s have a look at the dataset using show \n",
    "function in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f982a8ff-993c-46ef-b2ad-1aea455a4a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+-----------+--------+---------+-------+\n",
      "|rate_marriage| age|yrs_married|children|religious|affairs|\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "|            5|32.0|        6.0|     1.0|        3|      0|\n",
      "|            4|22.0|        2.5|     0.0|        2|      0|\n",
      "|            3|32.0|        9.0|     3.0|        3|      1|\n",
      "|            3|27.0|       13.0|     3.0|        1|      1|\n",
      "|            4|22.0|        2.5|     0.0|        1|      1|\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc8ee19-14dc-442f-b3dd-2f2a0c150d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "|summary|     rate_marriage|               age|      yrs_married|          children|         religious|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "|  count|              6366|              6366|             6366|              6366|              6366|\n",
      "|   mean| 4.109644989004084|29.082862079798932| 9.00942507068803|1.3968740182218033|2.4261702796104303|\n",
      "| stddev|0.9614295945655025| 6.847881883668817|7.280119972766412| 1.433470828560344|0.8783688402641785|\n",
      "|    min|                 1|              17.5|              0.5|               0.0|                 1|\n",
      "|    max|                 5|              42.0|             23.0|               5.5|                 4|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select('summary','rate_marriage','age', 'yrs_married','children','religious').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b81fda-0adf-4992-b857-2a483ae90e51",
   "metadata": {},
   "source": [
    "We can observe that the average age of people is close to 29 years, and \n",
    "they have been married for 9 year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7d47d-3921-481b-a005-a0572ce841fc",
   "metadata": {},
   "source": [
    "Let us explore individual columns to understand the data in deeper \n",
    "detail. The `groupBy` function used along with counts returns us the \n",
    "frequency of each of the categories in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf31fa6-76ad-48de-aa60-a25519577bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1| 2053|\n",
      "|      0| 4313|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1583a006-acf2-441b-9e86-e2626e9dc157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|rate_marriage|count|\n",
      "+-------------+-----+\n",
      "|            1|   99|\n",
      "|            3|  993|\n",
      "|            5| 2684|\n",
      "|            4| 2242|\n",
      "|            2|  348|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('rate_marriage').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f11cbc-20c5-4a1b-8f93-6d43f4e8d0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-----+\n",
      "|rate_marriage|affairs|count|\n",
      "+-------------+-------+-----+\n",
      "|            1|      0|   25|\n",
      "|            1|      1|   74|\n",
      "|            2|      0|  127|\n",
      "|            2|      1|  221|\n",
      "|            3|      0|  446|\n",
      "|            3|      1|  547|\n",
      "|            4|      0| 1518|\n",
      "|            4|      1|  724|\n",
      "|            5|      0| 2197|\n",
      "|            5|      1|  487|\n",
      "+-------------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('rate_marriage','affairs').count().orderBy('rate_marriage','affairs','count',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bbed995-aab5-4516-a2eb-b3dc3bf6609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+\n",
      "|religious|affairs|count|\n",
      "+---------+-------+-----+\n",
      "|        1|      0|  613|\n",
      "|        1|      1|  408|\n",
      "|        2|      0| 1448|\n",
      "|        2|      1|  819|\n",
      "|        3|      0| 1715|\n",
      "|        3|      1|  707|\n",
      "|        4|      0|  537|\n",
      "|        4|      1|  119|\n",
      "+---------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('religious','affairs').count().orderBy('religious','affairs','count',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d299be-368d-4483-b29f-3306c7ce57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+\n",
      "|children|affairs|count|\n",
      "+--------+-------+-----+\n",
      "|     0.0|      0| 1912|\n",
      "|     0.0|      1|  502|\n",
      "|     1.0|      0|  747|\n",
      "|     1.0|      1|  412|\n",
      "|     2.0|      0|  873|\n",
      "|     2.0|      1|  608|\n",
      "|     3.0|      0|  460|\n",
      "|     3.0|      1|  321|\n",
      "|     4.0|      0|  197|\n",
      "|     4.0|      1|  131|\n",
      "|     5.5|      0|  124|\n",
      "|     5.5|      1|   79|\n",
      "+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('children','affairs').count().orderBy('children','affairs','count',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc853335-7db2-4228-bade-0bd7395a94f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "|affairs|avg(rate_marriage)|          avg(age)|  avg(yrs_married)|     avg(children)|    avg(religious)|avg(affairs)|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "|      1|3.6473453482708234|30.537018996590355|11.152459814905017|1.7289332683877252| 2.261568436434486|         1.0|\n",
      "|      0| 4.329700904242986| 28.39067934152562| 7.989334569904939|1.2388128912589844|2.5045212149316023|         0.0|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ee668-4a1e-4bc6-bc76-a49c6d98daf1",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941859b2-a6af-47fe-b02c-aad4f493996c",
   "metadata": {},
   "source": [
    "This is the part where we create a single vector combining all input \n",
    "features by using Spark’s `VectorAssembler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b50be4fc-1410-41b4-8e68-86c51a1ae297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "df_assembler = VectorAssembler(inputCols=['rate_marriage', 'age', 'yrs_married', 'children', 'religious'], outputCol=\"features\")\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84162208-cb5c-454b-9ade-44c073e14f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rate_marriage: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- yrs_married: double (nullable = true)\n",
      " |-- children: double (nullable = true)\n",
      " |-- religious: integer (nullable = true)\n",
      " |-- affairs: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3c46a-6789-4baa-b196-6f5ab75d2c96",
   "metadata": {},
   "source": [
    "As we can see, now we have one extra column named features, which \n",
    "is nothing but a combination of all the input features represented as a \n",
    "single dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56727ef9-2c20-4378-a805-cd93bb02d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------+\n",
      "|features               |affairs|\n",
      "+-----------------------+-------+\n",
      "|[5.0,32.0,6.0,1.0,3.0] |0      |\n",
      "|[4.0,22.0,2.5,0.0,2.0] |0      |\n",
      "|[3.0,32.0,9.0,3.0,3.0] |1      |\n",
      "|[3.0,27.0,13.0,3.0,1.0]|1      |\n",
      "|[4.0,22.0,2.5,0.0,1.0] |1      |\n",
      "|[4.0,37.0,16.5,4.0,3.0]|1      |\n",
      "|[5.0,27.0,9.0,1.0,1.0] |1      |\n",
      "|[4.0,27.0,9.0,0.0,2.0] |1      |\n",
      "|[5.0,37.0,23.0,5.5,2.0]|1      |\n",
      "|[5.0,37.0,23.0,5.5,2.0]|1      |\n",
      "+-----------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features','affairs']).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ceb58-7c8f-4649-b2ee-6e6103404854",
   "metadata": {},
   "source": [
    "Let us select only the features column as input and the affairs column \n",
    "as output for training the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7213f105-8eba-4aee-b1ff-20375f58919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df.select(['features','affairs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06de46-81d2-46a9-a15e-e48da39ee565",
   "metadata": {},
   "source": [
    "## Step 5: Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d7e0b-7550-4a4d-9f3b-8f8c659cb520",
   "metadata": {},
   "source": [
    "We have to split the dataset into training and test datasets in order to train \n",
    "and evaluate the performance of the random forest model. We split it into \n",
    "a 75/25 ratio and train our model on 75% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b89d5240-b6d9-4aac-9774-8d909dcc3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4743\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = model_df.randomSplit([0.75,0.25])\n",
    "print(train_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f88a85a-4562-4e6a-91cf-5f7f8da9035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1| 1551|\n",
      "|      0| 3192|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b792e-291d-42cd-98a5-fb6d1da293cf",
   "metadata": {},
   "source": [
    "This ensures we have balanced set values for the target class (‘affairs’) \n",
    "into the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45adfd33-cbea-442f-b300-658c908fba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1|  502|\n",
      "|      0| 1121|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3267c-58f9-47d6-883d-75d87f91bd85",
   "metadata": {},
   "source": [
    "## Step 6: Build and Train Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bdae85-2522-4253-bc9f-886b1dbcdc25",
   "metadata": {},
   "source": [
    "In this part, we build and train the random forest model using features \n",
    "such as input and Status as the output colum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43fa2783-8402-4cb1-bce0-4562a8cddd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(labelCol='affairs', numTrees=50).fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751786f-30ce-4f8d-9ee5-ea7f07f21f3a",
   "metadata": {},
   "source": [
    "## Step 7: Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e8de7-dcb6-4f0f-932f-02ed3a6da81e",
   "metadata": {},
   "source": [
    "Once we have trained our model on the training dataset, we can evaluate \n",
    "its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd3496e1-3f76-48e7-880b-b0e482093f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|            features|affairs|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|[1.0,22.0,2.5,1.0...|      1|[25.4750535109005...|[0.50950107021801...|       0.0|\n",
      "|[1.0,27.0,2.5,1.0...|      1|[25.6910529703782...|[0.51382105940756...|       0.0|\n",
      "|[1.0,27.0,6.0,1.0...|      0|[17.2420790681183...|[0.34484158136236...|       1.0|\n",
      "|[1.0,27.0,6.0,1.0...|      0|[17.2420790681183...|[0.34484158136236...|       1.0|\n",
      "|[1.0,32.0,2.5,1.0...|      0|[25.3484798408766...|[0.50696959681753...|       0.0|\n",
      "|[1.0,32.0,13.0,0....|      1|[21.3084220071231...|[0.42616844014246...|       1.0|\n",
      "|[1.0,32.0,13.0,2....|      1|[13.9218400777464...|[0.27843680155492...|       1.0|\n",
      "|[1.0,32.0,16.5,2....|      1|[13.7206914983931...|[0.27441382996786...|       1.0|\n",
      "|[1.0,32.0,16.5,3....|      1|[15.6431715009444...|[0.31286343001888...|       1.0|\n",
      "|[1.0,32.0,16.5,3....|      1|[15.6431715009444...|[0.31286343001888...|       1.0|\n",
      "|[1.0,37.0,13.0,1....|      1|[23.5344923763126...|[0.47068984752625...|       1.0|\n",
      "|[1.0,37.0,13.0,2....|      0|[14.0038677275160...|[0.28007735455032...|       1.0|\n",
      "|[1.0,37.0,13.0,3....|      0|[24.4258109548802...|[0.48851621909760...|       1.0|\n",
      "|[1.0,37.0,16.5,3....|      1|[13.6911073863916...|[0.27382214772783...|       1.0|\n",
      "|[1.0,37.0,16.5,4....|      1|[13.7712218356048...|[0.27542443671209...|       1.0|\n",
      "|[1.0,37.0,23.0,5....|      1|[13.8512808922386...|[0.27702561784477...|       1.0|\n",
      "|[1.0,37.0,23.0,5....|      1|[23.5725017108595...|[0.47145003421719...|       1.0|\n",
      "|[1.0,42.0,16.5,1....|      1|[15.7744559037303...|[0.31548911807460...|       1.0|\n",
      "|[1.0,42.0,16.5,1....|      1|[15.8585587336858...|[0.31717117467371...|       1.0|\n",
      "|[1.0,42.0,16.5,5....|      1|[19.6357648231142...|[0.39271529646228...|       1.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf_classifier.transform(test_df)\n",
    "rf_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a659cc0b-359e-40e4-9e1f-41c73daf44b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0| 1340|\n",
      "|       1.0|  283|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51455140-ea75-44ff-818a-c29d5f659716",
   "metadata": {},
   "source": [
    "To evaluate these preditions, we will import the \n",
    "classificationEvaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b76976-d639-437d-9642-f12fec5ef353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db3f9b1-7cb4-4932-b01b-2a09c58c852c",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0320004-aaf0-4e67-beaa-05023b8819ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of RF on test data is 73%\n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = MulticlassClassificationEvaluator(labelCol='affairs',metricName='accuracy').evaluate(rf_predictions)\n",
    "print('The accuracy of RF on test data is {0:.0%}'.format(rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e559b0-3364-4f18-90b8-058b37a7cf4a",
   "metadata": {},
   "source": [
    "**Precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "512db678-bcbd-492e-8335-65b89949498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision rate on test data is 72%\n"
     ]
    }
   ],
   "source": [
    "rf_precision = MulticlassClassificationEvaluator(labelCol='affairs',metricName='weightedPrecision').evaluate(rf_predictions)\n",
    "print('The precision rate on test data is {0:.0%}'.format(rf_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae17bc-6d84-4974-bd19-787feb5b689e",
   "metadata": {},
   "source": [
    "**AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a44dc351-463b-42da-a887-a7aa1d2c9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7572226704244571\n"
     ]
    }
   ],
   "source": [
    "rf_auc = BinaryClassificationEvaluator(labelCol='affairs').evaluate(rf_predictions)\n",
    "print(rf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0c21c-3a24-405c-9d49-0bee6d107f1b",
   "metadata": {},
   "source": [
    "As mentioned in the earlier part, RF gives the importance of each \n",
    "feature in terms of predictive power, and it is very useful to figure out the \n",
    "critical variables that contribute the most to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8faa6682-821c-4fbc-8e85-c54d98fe584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.612, 1: 0.0217, 2: 0.2234, 3: 0.0636, 4: 0.0793})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba4af4-ebd0-40e2-bab0-d344a298b44f",
   "metadata": {},
   "source": [
    "We used five features and the importance can be found out using the \n",
    "feature importance function. To know which input feature is mapped to \n",
    "which index values, we can use metadata information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aef8f88c-168a-45fd-aaa9-57279b4dcf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numeric': [{'idx': 0, 'name': 'rate_marriage'},\n",
       "  {'idx': 1, 'name': 'age'},\n",
       "  {'idx': 2, 'name': 'yrs_married'},\n",
       "  {'idx': 3, 'name': 'children'},\n",
       "  {'idx': 4, 'name': 'religious'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf13cd-9105-4bf9-832d-4d348ef40871",
   "metadata": {},
   "source": [
    "So, rate_marriage is the most important feature from a prediction \n",
    "standpoint followed by yrs_married. The least significant variable seems to \n",
    "be Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7627b7c-1b8f-418d-9723-0d1483300b13",
   "metadata": {},
   "source": [
    "## Step 8: Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3188e9-3164-41ea-ae95-847633fdf41e",
   "metadata": {},
   "source": [
    "Save the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d20fc2c-cb7c-49ad-8b18-8deb364c9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "\n",
    "rf_classifier.save(\"./RF_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8ce77-b7de-4f81-9798-469bae401bab",
   "metadata": {},
   "source": [
    "Load the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83180cae-279b-4fb4-b03b-0ff98649f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassificationModel.load(\"./RF_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
