{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ddc3c59-898d-46ae-bdbe-a7a10184930d",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3a53c-b4e2-4cd3-b838-91fa56791fd7",
   "metadata": {},
   "source": [
    "## Step 1: Create the SparkSession Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f0e6f-7489-4b5b-9022-6382d5b563d2",
   "metadata": {},
   "source": [
    "We start the Jupyter Notebook and import SparkSession and create a new \n",
    "`SparkSession` object to use Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d7def5-5e7b-4871-b835-f487c36295e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6ad18d-3823-4c6c-8fc8-dd9df0214ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('lin_reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59401013-a586-4937-84ce-b7e01d97c9c7",
   "metadata": {},
   "source": [
    "## Step 2: Read the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b99762-9f4a-4efd-89aa-2e64b460659e",
   "metadata": {},
   "source": [
    "We then load and read the dataset within Spark using Dataframe. We have \n",
    "to make sure we have opened the PySpark from the same directory folder \n",
    "where the dataset is available or else we have to mention the directory path \n",
    "of the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66076a02-8e19-4a47-afc4-e8b8c5b2aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Linear_regression_dataset.csv', inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a5abb-e3bf-4305-8cb4-bd0143b0c99a",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e8a04b-f01d-42ad-8a8a-cb733fd13ec3",
   "metadata": {},
   "source": [
    "In this section, we drill deeper into the dataset by viewing the dataset, \n",
    "validating the shape of the dataset, various statistical measures, and \n",
    "correlations among input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40340dbc-5281-4ae3-b911-ad49cb85c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a2f26e-69e0-43b8-950f-80ed8432a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28046b5-c47d-47f6-97b5-d033c007645f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(var_1=734, var_2=688, var_3=81, var_4=0.328, var_5=0.259, output=0.418),\n",
       " Row(var_1=700, var_2=600, var_3=94, var_4=0.32, var_5=0.247, output=0.389),\n",
       " Row(var_1=712, var_2=705, var_3=93, var_4=0.311, var_5=0.247, output=0.417)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15446eb2-1add-4d82-9115-4d219b437c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|corr(var_1, output)|\n",
      "+-------------------+\n",
      "| 0.9187399607627283|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "df.select(corr('var_1','output')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f84e3-e2f9-4af5-bb95-0b3f96f67e00",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f5857-b643-4784-be79-9c381e944449",
   "metadata": {},
   "source": [
    "This is the part where we create a single vector combining all input features \n",
    "by using Sparkâ€™s `VectorAssembler`. It creates only a single feature that \n",
    "captures the input values for that row. So, instead of five input columns, it \n",
    "essentially merges all input columns into a single feature vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426b1031-1bce-4318-93c1-0d2d04739cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf36bd4-6617-483b-9012-f5fde1ebddce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'output']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6947a363-7ed1-4e56-a49c-f290c1680a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assmebler = VectorAssembler(inputCols=['var_1', 'var_2', 'var_3', 'var_4', 'var_5'], outputCol='features')\n",
    "\n",
    "features_df = vec_assmebler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77c92ce2-b43e-49fd-8611-2b8fdb2100c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45719dd0-4727-4b85-a234-04758f6c425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|features                      |\n",
      "+------------------------------+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|\n",
      "|[700.0,600.0,94.0,0.32,0.247] |\n",
      "|[712.0,705.0,93.0,0.311,0.247]|\n",
      "|[734.0,806.0,69.0,0.315,0.26] |\n",
      "|[613.0,759.0,61.0,0.302,0.24] |\n",
      "+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.select('features').show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff674a2c-5510-4ea2-bf89-8c4956822fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "|features                      |output|\n",
      "+------------------------------+------+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|0.418 |\n",
      "|[700.0,600.0,94.0,0.32,0.247] |0.389 |\n",
      "|[712.0,705.0,93.0,0.311,0.247]|0.417 |\n",
      "|[734.0,806.0,69.0,0.315,0.26] |0.415 |\n",
      "|[613.0,759.0,61.0,0.302,0.24] |0.378 |\n",
      "+------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df = features_df.select('features','output')\n",
    "model_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f022d66b-5c49-4422-b87d-629297ce37ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 2)\n"
     ]
    }
   ],
   "source": [
    "print((model_df.count(), len(model_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1e4d2-da0b-42a0-ac08-11c71793ad24",
   "metadata": {},
   "source": [
    "## Step 5: Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ac527-eb77-4750-8435-28741369f03b",
   "metadata": {},
   "source": [
    "We have to split the dataset into a training and test dataset in order to train \n",
    "and evaluate the performance of the Linear Regression model built. We \n",
    "split it into a 70/30 ratio and train our model on 70% of the dataset. We can \n",
    "print the shape of train and test data to validate the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e5f0383-3cac-45ef-be48-45dbfc078246",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=model_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "755c0b3e-c051-4e1c-a916-b01ac0beb098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 2)\n"
     ]
    }
   ],
   "source": [
    "print((train_df.count(), len(train_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6035bc-cada-40b6-93c6-cae9b54b5aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 2)\n"
     ]
    }
   ],
   "source": [
    "print((test_df.count(), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cb9d6-5046-45f0-a90c-8483fc50928d",
   "metadata": {},
   "source": [
    "## Step 6: Build and Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9951c6e-bc52-4709-98ab-e62838ef96d9",
   "metadata": {},
   "source": [
    "In this part, we build and train the Linear Regression model using features \n",
    "of the input and output columns. We can fetch the coefficients (B1, B2, \n",
    "B3, B4, B5) and intercept (B0) values of the model as well. We can also \n",
    "evaluate the performance of model on training data as well using r2. This \n",
    "model gives a very good accuracy (86%) on training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65da2512-d697-47c0-8fe2-d9613ded5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lin_Reg = LinearRegression(labelCol='output')\n",
    "\n",
    "lr_model = lin_Reg.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de97dfc-0a13-48fe-ac34-3c424c732345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0003416993111494008,5.3460409502920966e-05,0.00018721969114898545,-0.6379763976924058,0.4852854913533292]\n"
     ]
    }
   ],
   "source": [
    "print(lr_model.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a300182d-cc18-4b3f-b0aa-2342fc56ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18208587329270542\n"
     ]
    }
   ],
   "source": [
    "print(lr_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4a022c6-e515-4c6e-8153-b74abd0604c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = lr_model.evaluate(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a06b6bce-80d1-438b-83aa-ce7f0e9a3758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8691103397865702\n"
     ]
    }
   ],
   "source": [
    "print(training_predictions.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24798e-1868-421b-9c21-300b82879569",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Linear Regression Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eee1de-6c09-4997-890c-3553a8950803",
   "metadata": {},
   "source": [
    "The final part of this entire exercise is to check the performance of the model \n",
    "on unseen or test data. We use the evaluate function to make predictions for \n",
    "the test data and can use r2 to check the accuracy of the model on test data. \n",
    "The performance seems to be almost similar to that of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fee3d885-9d24-435b-8d18-288456161118",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = lr_model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d987487c-9d48-467a-b258-6e9827be2cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8691408114274075\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea4a572d-ceb0-4e9a-91da-e015814f0c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013818268764449108\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions.meanSquaredError)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
